{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f241b71-0ed7-4413-9348-29e48e4ed491",
   "metadata": {},
   "source": [
    "# üìù Ecommerce AI Agent (LangGraph)\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "- This notebook/script builds an advanced **ecommerce customer service AI agent**.\n",
    "- The agent is **modular**, able to answer FAQs, order status, refund, returns, and review queries.\n",
    "- **Semantic FAQ retrieval** is powered by embeddings + ChromaDB.\n",
    "- **Structured data** (orders, payments, reviews) is retrieved from your SQL database.\n",
    "- **Intent classification** is done using an LLM (OpenAI or open-source via HuggingFace).\n",
    "- All user **Q&A pairs are logged** for learning, retraining, and analytics.\n",
    "- **Workflow and tool orchestration** are handled by LangGraph for multi-step reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## Code Section Guide\n",
    "\n",
    "1. **Imports**  \n",
    "   _All required Python libraries are loaded here._\n",
    "\n",
    "2. **FAQ Vector Store**  \n",
    "   _Loads FAQ data, builds a semantic search index._\n",
    "\n",
    "3. **Database Connection**  \n",
    "   _Connects to your ecommerce database._\n",
    "\n",
    "4. **LLM Setup**  \n",
    "   _Configures LLM for intent classification (OpenAI or HuggingFaceHub)._\n",
    "\n",
    "5. **Tool Definitions**  \n",
    "   _Functions for each business operation (FAQ, order, refund, return, review)._\n",
    "\n",
    "6. **Memory**  \n",
    "   _Initializes a conversation buffer._\n",
    "\n",
    "7. **LangGraph Nodes**  \n",
    "   _Defines workflow steps for multi-step reasoning._\n",
    "\n",
    "8. **Build Workflow**  \n",
    "   _Wires agent steps together using LangGraph._\n",
    "\n",
    "9. **Chat Loop**  \n",
    "   _Interactive chat session (replace with API in production)._\n",
    "\n",
    "---\n",
    "\n",
    "## Customization/Extension Tips\n",
    "\n",
    "- **Add more tools:**  \n",
    "  Define new functions and update both the tools list and tool_node routing.\n",
    "\n",
    "- **Improve returns/refund logic:**  \n",
    "  Expand those functions to match your real processes and schema.\n",
    "\n",
    "- **Change LLM or database:**  \n",
    "  Update config and environment variables as needed.\n",
    "\n",
    "- **Deploy as API:**  \n",
    "  Replace the CLI chat loop with a FastAPI or Flask route.\n",
    "\n",
    "---\n",
    "\n",
    "## Security/Production Tips\n",
    "\n",
    "- **Do NOT hardcode credentials.** Use environment variables.\n",
    "- **Check and filter logs** for PII or sensitive info.\n",
    "- **Sanitize all user input** that hits the database.\n",
    "\n",
    "---\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [ChromaDB Documentation](https://docs.trychroma.com/)\n",
    "- [HuggingFace Hub](https://huggingface.co/)\n",
    "\n",
    "---\n",
    "\n",
    "## Questions?\n",
    "\n",
    "See the inline comments and docstrings, or ping the code owner for guidance!\n",
    "\n",
    "---\n",
    "\n",
    "## Ecommerce AI Agent (LangGraph) ‚Äî Jupyter Notebook Guide\n",
    "\n",
    "## Overview\n",
    "\n",
    "- Multi-tool, multi-intent AI agent for ecommerce support (LangChain + LangGraph).\n",
    "- Supports FAQ, order status, refund, return, reviews (semantic + DB).\n",
    "- Uses LLM for intent classification.\n",
    "- Every Q&A logged for future learning.\n",
    "- Easily extendable (more tools, APIs, memory).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cea4dd7-8eb2-4984-9be5-0409f5a4419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Dependencies\n",
    "# !pip install -q langchain langgraph langchain_community langchain_chroma chromadb sqlalchemy datasets openai langchain_huggingface huggingface_hub\n",
    "\n",
    "# =======================\n",
    "# 1. Setup: Imports\n",
    "# =======================\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "from datasets import load_dataset\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.tools import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from openai import OpenAI\n",
    "\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlalchemy import Table, Column, Integer, String, Float, MetaData\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b583c37-7d91-4c9f-94e6-9ad96ebb7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 2. FAQ Vector Store Setup\n",
    "# =======================\n",
    "# Loads FAQ data from Hugging Face and builds a semantic search vector DB (Chroma).\n",
    "\n",
    "# ---\n",
    "# Optional: Delete vector DB folder if you want to recreate it from scratch\n",
    "VECTOR_DB_DIR = \"./faq_vectorstore\"\n",
    "# if os.path.exists(VECTOR_DB_DIR):\n",
    "#     shutil.rmtree(VECTOR_DB_DIR)\n",
    "# ---\n",
    "faq_dataset = load_dataset(\"Andyrasika/Ecommerce_FAQ\")['train']\n",
    "faqs = [f\"{row['question']} {row['answer']}\" for row in faq_dataset]\n",
    "ids = [str(i) for i in range(len(faqs))]\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vector_db = Chroma(\n",
    "    collection_name=\"faq\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=VECTOR_DB_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7269216e-98f7-4df1-8719-c6362f78b6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store already exists. Skipping addition.\n"
     ]
    }
   ],
   "source": [
    "# Check if DB is empty\n",
    "if not vector_db.get()['ids']:\n",
    "    print(\"Adding FAQs to vector store...\")\n",
    "    vector_db.add_texts(faqs, ids=ids)\n",
    "    print(\"Vector store persisted.\")\n",
    "else:\n",
    "    print(\"Vector store already exists. Skipping addition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff322c0-18c9-4d3a-9bf4-80e4bca91522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database:olist.db already exists\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 3. Database Connection (from CSVs if no DB exists)\n",
    "# =======================\n",
    "# Loads CSVs into a fresh SQLite DB if not present, or connects directly if DB file already exists.\n",
    "DATABASE_FILE = \"olist.db\" \n",
    "DATABASE_URL = f\"sqlite:///{DATABASE_FILE}\"\n",
    "FOLDER = \"./data\"\n",
    "\n",
    "# Specify your CSV files and corresponding table names here\n",
    "csv_table_map = {\n",
    "    'olist_customers_dataset' : 'olist_customers_dataset.csv',\n",
    "    'olist_geolocation_dataset' : 'olist_geolocation_dataset.csv',\n",
    "    'olist_orders_dataset' : 'olist_orders_dataset.csv',\n",
    "    'olist_order_items_dataset' : 'olist_order_items_dataset.csv',\n",
    "    'olist_order_payments_dataset' : 'olist_order_payments_dataset.csv',\n",
    "    'olist_order_reviews_dataset' : 'olist_order_reviews_dataset.csv',\n",
    "    'olist_products_dataset' : 'olist_products_dataset.csv',\n",
    "    'olist_sellers_dataset' : 'olist_sellers_dataset.csv',\n",
    "    'product_category_name_translation' : 'product_category_name_translation.csv' \n",
    "}\n",
    "\n",
    "def create_db_from_csvs(csv_table_map, db_file, folder):\n",
    "    \"\"\"If db_file doesn't exist, create it and import all CSVs as tables.\"\"\"\n",
    "    if os.path.exists(db_file):\n",
    "        print(f\"Database:{db_file} already exists\")\n",
    "        return None\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    for table, csv in csv_table_map.items():\n",
    "        if not os.path.exists(f\"{folder}/{csv}\"):\n",
    "            print(f\"Warning: {folder}/{csv} not found. Skipping table {table}.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"Writing: {folder}/{csv} into {table}.\")\n",
    "        df = pd.read_csv(f\"{folder}/{csv}\")\n",
    "        df.to_sql(table, conn, index=False, if_exists='replace')\n",
    "    conn.close()\n",
    "\n",
    "# Only create DB from CSVs if DB file does not exist\n",
    "create_db_from_csvs(csv_table_map, DATABASE_FILE, FOLDER)\n",
    "\n",
    "# Now connect via SQLAlchemy as usual\n",
    "engine = create_engine(DATABASE_URL)\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "\n",
    "# You can now access your tables as before!\n",
    "olist_customers = metadata.tables.get('olist_customers_dataset')\n",
    "olist_geolocation = metadata.tables.get('olist_geolocation_dataset')\n",
    "olist_orders = metadata.tables.get('olist_orders_dataset')\n",
    "olist_order_items = metadata.tables.get('olist_order_items_dataset')\n",
    "olist_order_payments = metadata.tables.get('olist_order_payments_dataset')\n",
    "olist_order_reviews = metadata.tables.get('olist_order_reviews_dataset')\n",
    "olist_products = metadata.tables.get('olist_products_dataset')\n",
    "olist_sellers =\tmetadata.tables.get('olist_sellers_dataset')\n",
    "product_category_name_translation = metadata.tables.get('product_category_name_translation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceaf2598-b7c6-46af-a271-1f43e76c689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 4. LLM Setup (with .env support)\n",
    "# =======================\n",
    "# Supports OpenAI and HuggingFace models. Reads API keys from .env via python-dotenv.\n",
    "load_dotenv()  # Automatically loads variables from a .env file at project root\n",
    "\n",
    "def llm(prompt):\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages= prompt)    \n",
    "    intent = response.choices[0].message.content.strip().lower()\n",
    "    return intent\n",
    "\n",
    "# .env example (do NOT check your keys into version control):\n",
    "# OPENAI_API_KEY=sk-...your-openai-key...\n",
    "# HUGGINGFACEHUB_API_TOKEN=hf_...your-hf-token..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c0bf79-fae4-400b-8786-c95d4c1aa729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 5. Tool Definitions\n",
    "# =======================\n",
    "# Each function is a \"tool\" for one business task.\n",
    "# Tools use regex to extract elements from user queries.\n",
    "def search_faq(query):\n",
    "    \"\"\"Semantic search in FAQ vector DB.\"\"\"\n",
    "    docs = vector_db.similarity_search(query, k=2)\n",
    "    return \"\\n\".join([doc.page_content for doc in docs]) if docs else \"No relevant FAQ found.\"\n",
    "\n",
    "faq_tool = Tool(\n",
    "    name=\"faq_search\",\n",
    "    func=search_faq,\n",
    "    description=\"Semantic search in FAQ for general questions.\"\n",
    ")   \n",
    "\n",
    "def get_order_status(query):\n",
    "    \"\"\"Retrieve order status from DB using order_id.\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'(\\b[0-9a-f]{32,}\\b)', query)\n",
    "    order_id = match.group(1) if match else None\n",
    "    if order_id and olist_orders is not None:\n",
    "        with engine.connect() as conn:\n",
    "            res = conn.execute(\n",
    "                olist_orders.select().where(olist_orders.c.order_id == order_id)\n",
    "            ).fetchone()\n",
    "            if res:\n",
    "                return f\"Order {order_id} status: {res.order_status}, purchased: {res.order_purchase_timestamp}, estimated delivery: {res.order_estimated_delivery_date}\"\n",
    "            else:\n",
    "                return f\"No order found for ID: {order_id}.\"\n",
    "    else:\n",
    "        return \"Please provide a valid order ID.\"\n",
    "\n",
    "order_status_tool = Tool(\n",
    "    name=\"order_status_lookup\",\n",
    "    func=get_order_status,\n",
    "    description=\"Look up order status by order_id.\"\n",
    ")\n",
    "\n",
    "def get_refund_status(query):\n",
    "    \"\"\"Check refund/payment info for an order.\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'(\\b[0-9a-f]{32,}\\b)', query)\n",
    "    order_id = match.group(1) if match else None\n",
    "    payments_table = metadata.tables.get('olist_order_payments_dataset')\n",
    "    if not order_id or payments_table is None:\n",
    "        return \"Please provide a valid order ID.\"\n",
    "    with engine.connect() as conn:\n",
    "        res = conn.execute(\n",
    "            payments_table.select().where(payments_table.c.order_id == order_id)\n",
    "        ).fetchall()\n",
    "        if not res:\n",
    "            return f\"No payment info for order {order_id}.\"\n",
    "        total_paid = sum(r.payment_value for r in res)\n",
    "        if total_paid == 0:\n",
    "            return f\"Order {order_id} was fully refunded.\"\n",
    "        else:\n",
    "            return f\"Order {order_id} was paid {total_paid}, refund status unknown.\"\n",
    "\n",
    "refund_status_tool = Tool(\n",
    "    name=\"refund_status_lookup\",\n",
    "    func=get_refund_status,\n",
    "    description=\"Check if an order has been refunded by order_id.\"\n",
    ")\n",
    "\n",
    "def get_review(query):\n",
    "    \"\"\"Retrieve review score/message for an order.\"\"\"\n",
    "    import re\n",
    "    match = re.search(r'(\\b[0-9a-f]{32,}\\b)', query)\n",
    "    order_id = match.group(1) if match else None\n",
    "    reviews_table = metadata.tables.get('olist_order_reviews_dataset')\n",
    "    if not order_id or reviews_table is None:\n",
    "        return \"Please provide a valid order ID.\"\n",
    "    with engine.connect() as conn:\n",
    "        res = conn.execute(\n",
    "            reviews_table.select().where(reviews_table.c.order_id == order_id)\n",
    "        ).fetchone()\n",
    "        if not res:\n",
    "            return f\"No review found for order {order_id}.\"\n",
    "        return f\"Review for order {order_id}: Score {res.review_score} - {res.review_comment_message or 'No comment.'}\"\n",
    "\n",
    "review_tool = Tool(\n",
    "    name=\"review_lookup\",\n",
    "    func=get_review,\n",
    "    description=\"Retrieve review and score for an order by order_id.\"\n",
    ")\n",
    "\n",
    "tools = [faq_tool, order_status_tool, refund_status_tool, review_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83a4c23-e2c7-4830-a967-ccc716260b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 6. Memory\n",
    "# =======================\n",
    "checkpointer = InMemorySaver()  # Keeps conversation state in memory (can be swapped for DB, Redis, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0d84a0-3c22-4e83-8947-1f38caf8b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 7. LangGraph Nodes (Workflow)\n",
    "# =======================\n",
    "def perception_node(state):\n",
    "    \"\"\"LLM-based intent classification.\"\"\"\n",
    "    query = state[\"input\"]\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful intent classifier.\"},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            \"Classify the user's query into one of these intents: \"\n",
    "            \"faq, order_status, refund_status, review. \"\n",
    "            \"Respond with only the intent word, nothing else. \"\n",
    "            f\"Here is the query: {query}\"\n",
    "        )}\n",
    "    ]\n",
    "    intent = llm(prompt).strip().lower()\n",
    "    allowed = {\"faq\", \"order_status\", \"refund_status\", \"review\"}\n",
    "    if intent not in allowed:\n",
    "        if \"order\" in query:\n",
    "            intent = \"order_status\"\n",
    "        else:\n",
    "            intent = \"faq\"\n",
    "    state[\"classification\"] = intent\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a9a5e39-8939-47c3-89d2-e2d8b4ecb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_node(state):\n",
    "    \"\"\"Dispatch to the correct business logic tool based on classified intent.\"\"\"\n",
    "    classification = state[\"classification\"]\n",
    "    query = state[\"input\"]\n",
    "    if classification == \"order_status\":\n",
    "        state[\"tool_output\"] = get_order_status(query)\n",
    "    elif classification == \"faq\":\n",
    "        state[\"tool_output\"] = search_faq(query)\n",
    "    elif classification == \"refund_status\":\n",
    "        state[\"tool_output\"] = get_refund_status(query)\n",
    "    elif classification == \"return_status\":\n",
    "        state[\"tool_output\"] = get_return_status(query)\n",
    "    elif classification == \"review\":\n",
    "        state[\"tool_output\"] = get_review(query)\n",
    "    else:\n",
    "        state[\"tool_output\"] = \"I'm sorry, I could not classify your request.\"\n",
    "    return state\n",
    "\n",
    "def answer_node(state):\n",
    "    \"\"\"Wrap up the result for agent response.\"\"\"\n",
    "    answer = state[\"tool_output\"]\n",
    "    state[\"output\"] = answer\n",
    "    return state\n",
    "\n",
    "def log_interaction(user_query, agent_answer):\n",
    "    \"\"\"Log each Q&A for learning, retraining, or analytics.\"\"\"\n",
    "    with open(\"agent_interactions.log\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{datetime.datetime.now().isoformat()} | Q: {user_query} | A: {agent_answer}\\n\")\n",
    "\n",
    "def learning_node(state):\n",
    "    \"\"\"Learning step: log output for future improvement.\"\"\"\n",
    "    log_interaction(state[\"input\"], state[\"output\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc4960f-d64e-4051-81f3-833507e2e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================\n",
    "# 8. Build LangGraph Workflow (with InMemorySaver checkpointing)\n",
    "# =======================\n",
    "from typing import TypedDict\n",
    "\n",
    "# Define the state schema required for StateGraph as a TypedDict (not a plain dict!)\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    classification: str\n",
    "    tool_output: str\n",
    "    output: str\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"perception\", perception_node)\n",
    "workflow.add_node(\"tool_use\", tool_node)\n",
    "workflow.add_node(\"answer\", answer_node)\n",
    "workflow.add_node(\"learning\", learning_node)\n",
    "# The magic fix: add edge from __start__ to your entry node!\n",
    "workflow.add_edge(\"__start__\", \"perception\")\n",
    "workflow.add_edge(\"perception\", \"tool_use\")\n",
    "workflow.add_edge(\"tool_use\", \"answer\")\n",
    "workflow.add_edge(\"answer\", \"learning\")\n",
    "\n",
    "# For latest LangGraph, entry/finish nodes are set in compile as positional args!\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7e1bf-be3e-4e76-ac9f-cd1e5c414fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ecommerce AI Agent (type 'quit' to exit).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is the review for 00010242fe8c5a6d1ba2dd792cb16214?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Review for order 00010242fe8c5a6d1ba2dd792cb16214: Score 5 - Perfeito, produto entregue antes do combinado.\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 9. Chat Loop\n",
    "# =======================\n",
    "def ask_agent(user_query):\n",
    "    state = {\"input\": user_query}\n",
    "    result = graph.invoke(state)\n",
    "    return result[\"output\"]\n",
    "\n",
    "print(\"Ecommerce AI Agent (type 'quit' to exit).\")\n",
    "while True:\n",
    "    q = input(\"You: \")\n",
    "    if q.lower() in {\"quit\", \"exit\"}:\n",
    "        break\n",
    "    print(\"AI:\", ask_agent(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484917ec-93b3-4d7f-9440-2856dcc63ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
